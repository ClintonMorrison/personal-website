
Trying to model the stock market involves a lot of interesting problems. Beyond just being interesting, it's also potentially profitable. If you could perfectly predict which stock would increase the most each day you could make a lot of money.

I've been learning Golang[https://golang.org/] recently and trying to come up suitable personal projects to use it for. Stock analysis seemed like a good candidate. It will involve a lot of networking to fetch stock data. Performance is also important because I would need to run computationally expensive algorithms on very large sets of data.

The goal is an automated system which ingests weekly stock information and makes predictions about how the prices will move in the following week. Over the weekend the program would download all the prices from the previous week, run models on the new data, and output these predictions. The stock which is predicted to have the highest percent increase would be the best to invest in. I could buy the predicted stock on Monday, and hold it until Friday that week. If the prediction was accurate the price should have gone up and I will make money when I sell it on Friday.

I also want to say that stock analysis is a hard problem. I don't seriously expect to get any useful results from my work on this. It would be foolish to invest any real money with the predictions these kind of models make. I'm doing it because it's fun and interesting.

Also there's some code in this article. I've omitted some details and error handling to shorten the snippets included here. You can see the actual code on my GitHub[https://github.com/ClintonMorrison/crystal-ball].



Getting Company Data
---

As I said, the goal is to have a pipeline which can process stock prices on a weekly basis. There are APIs to get stock data but you need to know the tickers[https://www.investopedia.com/terms/s/stocksymbol.asp] for the stocks (for example the ticker for Apple is "AAPL"). So we first need to know what publicly traded companies exist, and what their tickers are. If we could collect some extra information about that would be even better, it might help build the models.

Manually cataloging this data is not a good idea, there's a lot of companies! At the time of writing there are 6,316 companies listed on the US stock exchanges. This system is supposed to be automated; you shouldn't have to manually enter information for new companies. Fortunately, there is a public API for getting this sort of data for companies on the NASDAQ and NYSE exchanges. You can download a CSV that includes company name, ticker, industry, sector, and market capitalization. The URL is:
```
http://www.nasdaq.com/screening/companies-by-industry.aspx?render=download
```

So we need a program which can download this data, parse it, and ideally dump it in a database so we can access it later. First, I made a struct for a "company":
```
type Company struct {
    Ticker       string
    Name         string
    LastSale     float64
    MarketCap    float64
    ADR          string
    TSO          string
    IPOYear      int64
    Sector       string
    Industry     string
    SummaryQuote string
}
```

Since the data comes from the API as a CSV we need to parse the values in the CSV and marshal it to our Company struct. The built-in encoding/csv package can actually do this.

```
func parseCompaniesFromCSV(ioReader io.Reader) map[string]Company {
    companies := make(map[string]Company)

    reader := csv.NewReader(ioReader)
    reader.Comma = ','

    for {
        record, err := reader.Read()

        if err == io.EOF {
            break
        }

        ticker := strings.TrimSpace(record[0])
        marketCap, _ := strconv.ParseFloat(record[3], 64)
        // etc.

        company := Company{
            symbol,
            name,
            lastTrade,
            marketCap,
            adr, tso,
            ipoyear,
            sector,
            industry,
            summaryQuote}

        companies[symbol] = company
    }

    return companies
}
```


Downloading this data with Go is really simple:

```
url := "http://www.nasdaq.com/screening/companies-by-industry.aspx?render=download"
resp, err := http.Get(url)
body, err := ioutil.ReadAll(resp.Body)
reader := bytes.NewReader(body)
companies := parseCompaniesFromCSV(reader)
```

 The result is a script that can be run every so often to download all the companies currently listed on the US stock exchanges. For this project I am storing the data in a Postgres database. See the "downloadCompanies.go" script in my GitHub[todo].



Getting Stock Data
---

Now that we have company data, we need the stock data! I said the system should handle weekly stock prices. There are not many free documented APIs for getting stock data. I am using AlphaVantage[https://www.alphavantage.co/documentation/]. They have a variety of APIs, including real time, daily, weekly, and monthly stock prices. They also have APIs for foreign and digital currencies. For my purposes I just want the weekly stock prices. To get all of the weekly prices for AAPL the request is:
```
https://www.alphavantage.co/query?
    function=TIME_SERIES_WEEKLY_ADJUSTED
    &apikey=...
    &outputsize=full
    &symbol=AAPL
```

Just like how I had a struct for companies, I also made a struct for weekly stock quotes:
```
type Quote struct {
	Ticker           string
	Date             time.Time
	Open             float64
	High             float64
	Low              float64
	Close            float64
	Volume           float64
	Dividend         float64
}
```

I wrote a script which loads the list of companies, and fetches the stock data for each company. The API returns the data as JSON, which can be parsed with the "encoding/json" package. The script then adds the relevant data for each quote to the Postgres database. See the "downloadQuotes.go" script in my GitHub[todo].

The rate limiting on the free tier of the AlphaVantage API is quite aggressive; they only allow 5 requests per minute. Since there are 6,316 companies it takes quite a long time to download all the data:
```
6316 / 5 = 1263.2 minutes = 21.05 hours
```

This is a long wait but it's okay since we only need to get new predictions once per week.

Model Variables
---
So, we have the company data, and we have the stock data! We even have programs to download new company and price data each week. We can examine, slice, and combine it by querying the database.

Now the hard part: predicting the future.

We have to assume that future behaviour will be related to the past. Hopefully there is some combination of variables to look at that can be used to predict how the stock will behave in the near future. There's lots of data to look at. For each company we have:
## name
## ticker
## market capitalization
## IPO year
## sector (e.g. "technology" or "finance")
## industry (e.g. "pre-packaged software" or "major banks")

<br/>
For each week for each company we have:
## Open price
## Close price
## High price
## Low price
## Volume (number of trades in that week)
## Dividend (amount issued that week)

<br/>
Two derived variables that are also useful are:
## Change (difference between the weekly open and close)
## Volatility (difference between the weekly high and low)

Models could base their predictions on just a few or all of these variables. Some of them might have no predictive power while others are useful to consider.

The goal is to, given all of this information, predict the percent change for the following week for every company.


NGrams
---
N-grams are a simple and popular approach to analyzing text. The idea is to look at text as an overlapping sequence of "grams", or combinations of characters. It's easiest to understand with an example. Consider the text "ABBAB".

These 1-grams for this text are:
```
"A", "B", "B", "A", "B"
```

The 2-grams are:
```
"AB", "BB", "BA", "AB"
```

The 3-grams are:
```
"ABB", "BBA", "BAB"
```

It's useful to count the occurrences of each possible n-gram, this allows us to see patterns. The possible 2-grams for the above example are "AA", "AB", "BA", and "BB". The 2-gram counts for "ABBAB" are bellow.

```table
2-gram, Count, Frequency
AA, 0, 0%
AB, 2, 50%
BA, 1, 25%
BB, 1, 25%
```

This shows that A is always followed by B, where as B is followed by A or B equally frequently.


Stock Prices As Text
---
You could look at a stock's history as a series of changes: one week it goes up a few percent, the next it stays fairly constant, and than the following week it's down a little. This is a natural way to look at it because it's exactly what we're trying to predict.

Numbers are hard to work with, they're very specific. It would be hard to predict that a stock will go up by exactly 13%. It seems like it would be easier to predict "it will go up a lot" or "it won't change much". For the purposes of simplying the problem and finding patterns, I thought it would be useful to reduce stock histories to a simpler form.

Along those lines, I came up with a scheme for giving a stock a "grade" for each week.
## A: the stock increased (by more than 1%)
## B: the stock did not change much (increase by less than 1%, or decreased by less than 1%)
## C: the stock decreased (by more than 1%)

<br/>
Consider the Apple stock for the last few weeks.


```table
Week, Open, Close, Change, Grade
August 10 - 17, $207.70, $217.58, 4.76% increase, A
August 17 - 24, $218.10, $216.16, 0.89% decrease, B
August 24 - 31, $217.65, $227.63, 4.67% increase, A
```

So for the first week it gets it get's "A". For the second "B", and the third "A". We can represent this as the string: "ABA". What is interesting about this is that it's now a text processing problem. We can try to use ngrams and other text processing techniques to try and learn about the patterns. For example if stocks that went up a lot the previous week are likely to go up the next week the ngram "AAA" should be common. If stocks that went down a lot the previous two weeks tend to level out the ngram "CCB" should be common.


Predictions With N-Gram Models
---

So we compute the grade text for each stock by looking at the weekly changes and assigning every week a grade. Once we have the text for every company we can count the n-grams in each. The idea is that the patterns that appeared in the past will appear in the future too. For example if "CCC" was usually followed by "A" in the past, we assume it will usually be followed by "A" in the future too.

To come up with a prediction we can consider if the n-grams with "A", "B", or "C" are most likely. For example if a stock went up for the last 2 weeks it would have the grade text "AA". To predict what will happen next we can consider the 3-grams "AAA", "AAB", "AAC". Whichever one is most common is what we will predict.



When we are counting the n-grams, there is a few ways to group the counts:
## company
## industry
## sector
## all together

That is, we count them separately for each company, we combine counts for companies with the same industry, we combine counts for companies in the same sector, or we just combine all the counts. Which of these will work best? It's hard to say. We need to try to model on the data and see how it performs.

I set up an experiment to compare these different ways to group the data. The experiment is then repeated for every way to group the data, and for an ng-ram length of 2, 3, 4, ..., up to 18.

Each model was trained with stock prices from the beginning of time up to January 1, 2018. To test the models, each one was used to predict the price change for the next week. The code compared the predicted change to the actual change to determine the percentage correct for each model. The below graph summaries the results:

%% IMAGE, model_performance.png, CENTER %%

The best performance was when all of the stock price n-grams were counted together (the green line) with an n-gram length of 3. For all of the ways to group the data, n-grams between 2 and 4 characters worked best. 

Trends
---

I wrote code to get the prices for each stock, convert it to text using the scheme I just described. With my program you can run the command:
```
./stockAnalysis -print-ngrams
```

It gets the full grade text for every stock and counts all the 1-grams, 2-grams, and 3-grams. The results are below. This is based on US stock market data from January 1995 to October 2018. The following 3 tables show the results.

```table
1-gram, Count, Frequency
C, 1102100, 26.42%
B, 1510621, 36.21%
A, 1559272, 37.37%
```

```table
2-gram, Count, Frequency
BC, 314880, 7.56%
CB, 325746, 7.82%
CA, 351449, 8.44%
AC, 362142, 8.69%
CC, 423076, 10.16%
BB, 575317, 13.81%
AA, 588718, 14.13%
AB, 607395, 14.58%
BA, 616930, 14.81%
```

```table
3-gram, Count, Frequency
CBC, 89130, 2.14%
BCC, 91220, 2.19%
CCB, 97430, 2.34%
BBC, 102502, 2.46%
CAC, 106018, 2.55%
BCB, 107729, 2.59%
CCA, 108067, 2.60%
CBB, 110544, 2.66%
ACC, 113877, 2.74%
BCA, 115038, 2.77%
ACB, 120160, 2.89%
CAB, 121674, 2.93%
ABC, 122791, 2.95%
CAA, 123546, 2.97%
CBA, 125098, 3.01%
BAC, 127708, 3.07%
ACA, 127832, 3.07%
AAC, 127923, 3.08%
CCC, 216916, 5.22%
AAA, 227290, 5.46%
BBB, 227770, 5.48%
AAB, 233264, 5.61%
ABB, 236091, 5.68%
BAA, 237113, 5.70%
BBA, 243468, 5.85%
ABA, 247570, 5.95%
BAB, 251544, 6.05%
```

Making Predictions!
---


Alternative Models
---


Evaluation
---


Building a Pipeline
---


Conclusion
---
